import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt

# Streamlit App Titel
st.title("ğŸ“Š Amazon Lagerbestands-Analyse Tool")
st.write("Lade die Lagerbestandsdatei hoch und erhalte umfassende Analysen zu VerkÃ¤ufen, Lagerbewegungen und Retouren.")

# Datei-Upload
uploaded_file = st.file_uploader("ğŸ“‚ Lade deine Amazon Lagerbestands-Datei hoch (CSV oder Excel)", type=["csv", "xlsx"])

if uploaded_file is not None:
    # Datei einlesen
    if uploaded_file.name.endswith(".csv"):
        df = pd.read_csv(uploaded_file, encoding="ISO-8859-1")
    else:
        df = pd.read_excel(uploaded_file)
    
    st.subheader("ğŸ” Vorschau der Daten")
    st.dataframe(df.head())
    
    # ZeitrÃ¤ume auswÃ¤hlen
    zeitraum = st.selectbox("ğŸ“… WÃ¤hle den Zeitraum fÃ¼r die Analyse", [
        "Letzter Tag (gestern)", "In den letzten 3 Tagen", "In den letzten 7 Tagen", "In den letzten 14 Tagen",
        "Letzte 30 Tage", "In den letzten 90 Tagen", "In den letzten 180 Tagen", "In den letzten 365 Tagen"])
    
    # Vergleich verschiedener ZeitrÃ¤ume
    st.subheader("ğŸ“Š Vergleich von ZeitrÃ¤umen")
    zeitraum_vergleich = st.selectbox("ğŸ“… WÃ¤hle einen zweiten Zeitraum zum Vergleich", [
        "Keine Vergleich", "In den letzten 3 Tagen", "In den letzten 7 Tagen", "In den letzten 14 Tagen",
        "Letzte 30 Tage", "In den letzten 90 Tagen"])
    
    # Event-Typ Filter
    event_type = st.selectbox("ğŸ”„ WÃ¤hle den Event-Typ", df["Event Type"].unique())
    df_filtered = df[df["Event Type"] == event_type]
    
    # Verkaufsanalyse nach MSKU und ASIN
    st.subheader("ğŸ“¦ Verkaufs- und Lagerbewegungsanalyse")
    if "MSKU" in df.columns and "Quantity" in df.columns:
        verkauf_sku = df_filtered.groupby(["MSKU", "ASIN", "Title"])["Quantity"].sum().sort_values(ascending=False)
        st.write("### Top 10 Produkte nach Anzahl Bewegungen")
        st.dataframe(verkauf_sku.head(10))
        
        # Visualisierung der VerkÃ¤ufe
        fig, ax = plt.subplots()
        verkauf_sku.head(10).plot(kind='bar', ax=ax)
        plt.xticks(rotation=45)
        plt.ylabel("Bewegte Menge (Einheiten)")
        st.pyplot(fig)
    else:
        st.warning("Die Datei scheint nicht die erwarteten Spalten zu enthalten. Stelle sicher, dass `MSKU` und `Quantity` vorhanden sind.")
    
    # Retourenanalyse
    st.subheader("ğŸ”„ Retouren-Analyse")
    if "Event Type" in df.columns and "Quantity" in df.columns:
        retouren = df[df["Event Type"].str.contains("Return", na=False)]
        retouren_sku = retouren.groupby(["MSKU", "ASIN", "Title"])["Quantity"].sum().sort_values(ascending=False)
        
        st.write("### Top 10 Produkte mit den meisten Retouren")
        st.dataframe(retouren_sku.head(10))
        
        # Retouren-Visualisierung
        fig, ax = plt.subplots()
        retouren_sku.head(10).plot(kind='bar', ax=ax)
        plt.xticks(rotation=45)
        plt.ylabel("Retouren (Einheiten)")
        st.pyplot(fig)
    else:
        st.warning("Keine Retouren-Daten gefunden.")
    
    # Anomalie-Erkennung: PlÃ¶tzlicher Verkaufsanstieg oder Retourenspitzen
    st.subheader("âš ï¸ Anomalie-Erkennung")
    threshold = st.slider("ğŸ“ˆ Setze die Schwelle fÃ¼r eine ungewÃ¶hnliche VerÃ¤nderung (z. B. 50%)", 10, 100, 50)
    verkauf_sku_change = verkauf_sku.pct_change().fillna(0) * 100
    anomalien = verkauf_sku_change[verkauf_sku_change.abs() > threshold]
    if not anomalien.empty:
        st.warning("ğŸš¨ UngewÃ¶hnliche VerÃ¤nderungen erkannt!")
        st.dataframe(anomalien)
    else:
        st.success("âœ… Keine ungewÃ¶hnlichen VerÃ¤nderungen erkannt.")
    
    # Lagerbestandsentwicklung
    st.subheader("ğŸ“‰ Lagerbestandsverlauf")
    if "Date and Time" in df.columns:
        df["Date and Time"] = pd.to_datetime(df["Date and Time"])
        df_sorted = df.sort_values(by=["Date and Time"])
        bestandsverlauf = df_sorted.groupby(["Date and Time", "MSKU"]).sum()["Quantity"].unstack().fillna(0)
        st.line_chart(bestandsverlauf)
    
    # Export der Ergebnisse
    st.subheader("ğŸ“¤ Export")
    if st.button("Export als CSV"):
        df_filtered.to_csv("amazon_analysen_export.csv", index=False)
        st.success("Datei erfolgreich gespeichert: amazon_analysen_export.csv")

# GitHub Dateien erstellen
with open("requirements.txt", "w") as req_file:
    req_file.write("streamlit\npandas\nmatplotlib")

with open(".gitignore", "w") as gitignore:
    gitignore.write("__pycache__/\n*.csv\n*.xlsx\n.env")

with open("README.md", "w") as readme:
    readme.write("""
# Amazon Lagerbestands-Analyse Tool

Dieses Tool analysiert Amazon-Lagerbestandsberichte und bietet umfassende Einblicke in VerkÃ¤ufe, Retouren und Lagerbewegungen.

## Neue Features:
- ğŸ“Š **Vergleich von ZeitrÃ¤umen**
- ğŸ“‰ **Lagerbestandsverlauf Ã¼ber die Zeit**
- âš ï¸ **Anomalie-Erkennung fÃ¼r plÃ¶tzliche VerÃ¤nderungen**
- ğŸ“¦ **Erweiterte Lagerbestandsanalyse**

## Installation
1. Python 3 installieren
2. BenÃ¶tigte Pakete installieren:
   ```
   pip install -r requirements.txt
   ```
3. Das Tool starten:
   ```
   streamlit run app.py
   ```

## Nutzung
1. Amazon-Lagerbestandsbericht hochladen (CSV/Excel)
2. Analysezeitraum auswÃ¤hlen & Vergleich aktivieren
3. Anomalie-Erkennung nutzen
4. Lagerbestandsentwicklung analysieren
5. Ergebnisse exportieren

""")